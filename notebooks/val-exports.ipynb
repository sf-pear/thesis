{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'auv450' : '/mnt/c/Users/sabri/Documents/github/thesis-edge/models/auv450.pt',\n",
    "    'onnx' : '/mnt/c/Users/sabri/Documents/github/thesis/models/auv/exports/auv450.onnx',\n",
    "    'tf_32' : '/mnt/c/Users/sabri/Documents/github/thesis/models/auv/exports/auv450_saved_model/auv450_float32.tflite',\n",
    "    'tf_16' : '/mnt/c/Users/sabri/Documents/github/thesis/models/auv/exports/auv450_saved_model/auv450_float16.tflite',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comment out - takes long to run and it's already done\n",
    "# auv_val = pd.DataFrame()\n",
    "\n",
    "# for key, value in models.items():\n",
    "#     model = YOLO(value, task='detect')  \n",
    "#     metrics = model.val(data='/mnt/c/Users/sabri/Documents/github/thesis/datasets/processed/auv/dataset.yaml', imgsz=1280, batch=1) \n",
    "\n",
    "#     info = metrics.results_dict\n",
    "#     info.update(metrics.speed)\n",
    "#     info_df = pd.DataFrame(info, index=[key])\n",
    "\n",
    "#     auv_val = pd.concat([auv_val, info_df])\n",
    "\n",
    "# auv_val.to_csv(\"/mnt/c/Users/sabri/Documents/github/thesis/artifacts/results/auv_edge_val.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alif-he',\n",
       " 'alif-hp',\n",
       " 'arduino-nano-33-ble',\n",
       " 'arduino-nicla-vision',\n",
       " 'portenta-h7',\n",
       " 'brainchip-akd1000',\n",
       " 'cortex-m4f-80mhz',\n",
       " 'cortex-m7-216mhz',\n",
       " 'espressif-esp32',\n",
       " 'himax-we-i',\n",
       " 'infineon-cy8ckit-062s2',\n",
       " 'infineon-cy8ckit-062-ble',\n",
       " 'jetson-nano',\n",
       " 'mbp-16-2020',\n",
       " 'nordic-nrf52840-dk',\n",
       " 'nordic-nrf5340-dk',\n",
       " 'nordic-nrf9160-dk',\n",
       " 'raspberry-pi-4',\n",
       " 'raspberry-pi-rp2040',\n",
       " 'renesas-ck-ra6m5',\n",
       " 'renesas-rzv2l-cpu',\n",
       " 'renesas-rzv2l',\n",
       " 'st-iot-discovery-kit',\n",
       " 'seeed-sense-cap',\n",
       " 'wio-terminal',\n",
       " 'seeed-vision-ai',\n",
       " 'silabs-xg24',\n",
       " 'silabs-thunderboard-sense-2',\n",
       " 'sony-spresense',\n",
       " 'synaptics-ka10000',\n",
       " 'ti-launchxl',\n",
       " 'ti-tda4vm']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import edgeimpulse as ei\n",
    "\n",
    "# Change to an API key from your Edge Impulse project\n",
    "ei.API_KEY = \"ei_2ee4112aa409b6bfa65c06d877bccd629408584d190ded67\"\n",
    "\n",
    "ei.model.list_profile_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance on device types:\n",
      "============================\n",
      "{\n",
      "    \"variant\": \"float32\",\n",
      "    \"lowEndMcu\": {\n",
      "        \"description\": \"Estimate for a Cortex-M0+ or similar, running at 40MHz\",\n",
      "        \"memory\": {},\n",
      "        \"supported\": false,\n",
      "        \"mcuSupportError\": \"Failed to get registration from op code CUSTOM\\n\\nFailed starting model allocation.\\n\\n\"\n",
      "    },\n",
      "    \"highEndMcu\": {\n",
      "        \"description\": \"Estimate for a Cortex-M7 or other high-end MCU/DSP, running at 240MHz\",\n",
      "        \"memory\": {},\n",
      "        \"supported\": false,\n",
      "        \"mcuSupportError\": \"Failed to get registration from op code CUSTOM\\n\\nFailed starting model allocation.\\n\\n\"\n",
      "    },\n",
      "    \"highEndMcuPlusAccelerator\": {\n",
      "        \"description\": \"Most accelerators only accelerate quantized models.\",\n",
      "        \"memory\": {},\n",
      "        \"supported\": false,\n",
      "        \"mcuSupportError\": \"Failed to get registration from op code CUSTOM\\n\\nFailed starting model allocation.\\n\\n\"\n",
      "    },\n",
      "    \"mpu\": {\n",
      "        \"description\": \"Estimate for a Cortex-A72, x86 or other mid-range microprocessor running at 1.5GHz\",\n",
      "        \"rom\": 174946596.0,\n",
      "        \"supported\": true\n",
      "    },\n",
      "    \"gpuOrMpuAccelerator\": {\n",
      "        \"description\": \"Estimate for a GPU or high-end neural network accelerator\",\n",
      "        \"rom\": 174946596.0,\n",
      "        \"supported\": true\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Print inference estimates\n",
    "result = ei.model.profile(model=models['onnx'])\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-20 21:58:56.545367: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-04-20 21:58:56.770311: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-04-20 21:58:56.771452: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-20 21:58:58.260739: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target results for float32:\n",
      "===========================\n",
      "{\n",
      "    \"device\": \"jetson-nano\",\n",
      "    \"tfliteFileSizeBytes\": 87535435,\n",
      "    \"isSupportedOnMcu\": false,\n",
      "    \"timePerInferenceMs\": 182412,\n",
      "    \"mcuSupportError\": \"edge-impulse-sdk/tensorflow/lite/micro/kernels/dequantize.cc:59 input->type == kTfLiteUInt8 || input->type == kTfLiteInt8 || input->type == kTfLiteInt16 was not true.\\nNode DEQUANTIZE (number 0f) failed to prepare with status 1\\n\"\n",
      "}\n",
      "\n",
      "\n",
      "Performance on device types:\n",
      "============================\n",
      "{\n",
      "    \"variant\": \"float32\",\n",
      "    \"lowEndMcu\": {\n",
      "        \"description\": \"Estimate for a Cortex-M0+ or similar, running at 40MHz\",\n",
      "        \"timePerInferenceMs\": 1021967266,\n",
      "        \"memory\": {},\n",
      "        \"supported\": false,\n",
      "        \"mcuSupportError\": \"edge-impulse-sdk/tensorflow/lite/micro/kernels/dequantize.cc:59 input->type == kTfLiteUInt8 || input->type == kTfLiteInt8 || input->type == kTfLiteInt16 was not true.\\nNode DEQUANTIZE (number 0f) failed to prepare with status 1\\n\"\n",
      "    },\n",
      "    \"highEndMcu\": {\n",
      "        \"description\": \"Estimate for a Cortex-M7 or other high-end MCU/DSP, running at 240MHz\",\n",
      "        \"timePerInferenceMs\": 13904542,\n",
      "        \"memory\": {},\n",
      "        \"supported\": false,\n",
      "        \"mcuSupportError\": \"edge-impulse-sdk/tensorflow/lite/micro/kernels/dequantize.cc:59 input->type == kTfLiteUInt8 || input->type == kTfLiteInt8 || input->type == kTfLiteInt16 was not true.\\nNode DEQUANTIZE (number 0f) failed to prepare with status 1\\n\"\n",
      "    },\n",
      "    \"highEndMcuPlusAccelerator\": {\n",
      "        \"description\": \"Most accelerators only accelerate quantized models.\",\n",
      "        \"timePerInferenceMs\": 13904542,\n",
      "        \"memory\": {},\n",
      "        \"supported\": false,\n",
      "        \"mcuSupportError\": \"edge-impulse-sdk/tensorflow/lite/micro/kernels/dequantize.cc:59 input->type == kTfLiteUInt8 || input->type == kTfLiteInt8 || input->type == kTfLiteInt16 was not true.\\nNode DEQUANTIZE (number 0f) failed to prepare with status 1\\n\"\n",
      "    },\n",
      "    \"mpu\": {\n",
      "        \"description\": \"Estimate for a Cortex-A72, x86 or other mid-range microprocessor running at 1.5GHz\",\n",
      "        \"timePerInferenceMs\": 240643,\n",
      "        \"rom\": 87535435.0,\n",
      "        \"supported\": true\n",
      "    },\n",
      "    \"gpuOrMpuAccelerator\": {\n",
      "        \"description\": \"Estimate for a GPU or high-end neural network accelerator\",\n",
      "        \"timePerInferenceMs\": 40108,\n",
      "        \"rom\": 87535435.0,\n",
      "        \"supported\": true\n",
      "    }\n",
      "}\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "profile = ei.model.profile(model=models['tf_16'], device='jetson-nano')\n",
    "print(profile.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ocean",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
