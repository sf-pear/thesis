{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect dataset with FiftyOne"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First set the path and dataset name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"/mnt/c/Users/sabri/Documents/github/thesis/datasets/auv\"\n",
    "# PATH = \"/home/sabf/thesis/thesis/datasets/rov/\"\n",
    "DATASET_NAME = \"auv\"\n",
    "DELETE_ALL_DATASETS = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiftyone as fo\n",
    "\n",
    "existent_datasets = fo.list_datasets()\n",
    "print(existent_datasets)\n",
    "\n",
    "if DELETE_ALL_DATASETS:\n",
    "    if len(existent_datasets) != 0: \n",
    "        for d in existent_datasets:\n",
    "            dataset = fo.load_dataset(d)\n",
    "            print(\"{d} deleted.\")\n",
    "            dataset.delete()\n",
    "        print(\"All existent datasets deleted.\")\n",
    "    else:\n",
    "        print(\"No datasets existent, nothing was deleted.\")\n",
    "else:\n",
    "    print(\"Set to false. Nothing was deleted.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['auv', 'auv2', 'rov', 'rov2']\n"
     ]
    }
   ],
   "source": [
    "import fiftyone as fo\n",
    "\n",
    "existent_datasets = fo.list_datasets()\n",
    "print(existent_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delete_this = fo.load_dataset('rov2')\n",
    "delete_this.delete()\n",
    "existent_datasets = fo.list_datasets()\n",
    "existent_datasets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DATASET_NAME in existent_datasets:\n",
    "    dataset = fo.load_dataset(DATASET_NAME)\n",
    "    print(\"Dataset loaded.\\n\")\n",
    "else:\n",
    "    # The splits to load\n",
    "    splits = [\"train\", \"val\", \"test\"]\n",
    "\n",
    "    # Load the dataset, using tags to mark the samples in each split\n",
    "    dataset = fo.Dataset(DATASET_NAME)\n",
    "    for split in splits:\n",
    "        dataset.add_dir(\n",
    "            dataset_dir=PATH,\n",
    "            dataset_type=fo.types.YOLOv5Dataset,\n",
    "            split=split,\n",
    "            tags=split,\n",
    "    )\n",
    "    print(\"Dataset created.\\n\")\n",
    "\n",
    "# View summary info about the dataset\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fo.pprint(dataset.stats(include_media=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the dataset persistent\n",
    "dataset.persistent = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the first few samples in the dataset\n",
    "print(dataset.head())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label distribution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "splits = [\"train\", \"val\", \"test\"]\n",
    "\n",
    "\n",
    "def make_df(splits):\n",
    "    \"\"\"Counts how many annotations of each label exist per split.\n",
    "\n",
    "    Args:\n",
    "        splits (list): List of splits in the fiftyone dataset. E.g.: ['train', 'test']\n",
    "\n",
    "    Returns:\n",
    "        pandas DataFrame: label, count and split columns.\n",
    "    \"\"\"    \n",
    "    df_list = []\n",
    "    for i in splits:\n",
    "        view = dataset.match_tags(i)\n",
    "        count_dict = view.count_values(\"ground_truth.detections.label\")\n",
    "\n",
    "        df = pd.DataFrame(count_dict.items(), columns=['label', 'count']).copy()\n",
    "        df[\"split\"] = i\n",
    "        df_list.append(df)\n",
    "    \n",
    "    return pd.concat(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_count = make_df([\"train\", \"val\", \"test\"])\n",
    "label_count.head()\n",
    "# save label counts\n",
    "# label_count.to_csv(\"../results/label_count_split.csv\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualising label counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# sort by count, more labels first\n",
    "sorted_df = label_count.sort_values(by='count', ascending=False)\n",
    "\n",
    "# plot label counts\n",
    "label_dist = sns.lineplot(data=sorted_df, x=\"label\", y=\"count\", hue=\"split\", palette=\"mako\")\n",
    "label_dist.set_xticklabels(label_dist.get_xticklabels(), rotation=45, horizontalalignment='right');"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Launch app\n",
    "Have a look at the actual dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = fo.launch_app(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fo.close_app()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing uniqueness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiftyone.brain as fob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fob.compute_uniqueness(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fo.close_app()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort in increasing order of uniqueness (least unique first)\n",
    "sorted_dataset = dataset.sort_by(\"uniqueness\")\n",
    "\n",
    "print(sorted_dataset.first())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open view in the App\n",
    "session.view = sorted_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'filename': sorted_dataset.values(\"filepath\"), 'uniqueness': sorted_dataset.values(\"uniqueness\")}).sort_values('uniqueness', ascending=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save uniqueness df to csv\n",
    "# df.to_csv(\"auv_uniqueness.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
